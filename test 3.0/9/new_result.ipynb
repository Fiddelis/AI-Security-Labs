{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55e08d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc749f15",
   "metadata": {},
   "source": [
    "## Redução de linhas por modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027459f",
   "metadata": {},
   "source": [
    "## Tempo medio de cada modelo por fontes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda8625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70937f97",
   "metadata": {},
   "source": [
    "## Precisão dos modelos por fontes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85c002",
   "metadata": {},
   "source": [
    "### Inferências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f352986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_analysis_data(analysis_str):\n",
    "    # Primeiro tenta com blocos markdown\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", analysis_str, re.DOTALL)\n",
    "    if not match:\n",
    "        # fallback: tenta pegar qualquer JSON com CLASSIFICATION\n",
    "        match = re.search(r\"\\{[^{}]*\\\"CLASSIFICATION\\\"[^{}]*\\}\", analysis_str, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(1 if '```' in match.group(0) else 0))\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Encontrar todos os arquivos JSONL no padrão especificado\n",
    "files = glob.glob('inference/**/*.jsonl', recursive=True)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_path in files:\n",
    "    # Extrair o modelo do caminho do arquivo\n",
    "    path = Path(file_path)\n",
    "    model = path.parts[1]  # Extrai o segundo componente do caminho (inference/{model}/...)\n",
    "    if(path.parts[2] == \"data\"):\n",
    "        font = path.parts[2]\n",
    "        type = path.parts[3]\n",
    "    else:\n",
    "        font = path.parts[3]\n",
    "        type = path.parts[4]\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                analysis_data = extract_analysis_data(record.get('analysis', ''))\n",
    "\n",
    "                data.append({\n",
    "                    'model': model,\n",
    "                    'type': type,\n",
    "                    'font': font,\n",
    "                    'source_file': record.get('file', ''),\n",
    "                    'classification': analysis_data.get('CLASSIFICATION', \"NOT INTERESTING\") if analysis_data else \"NOT INTERESTING\",\n",
    "                    'confidence': analysis_data.get('CONFIDENCE', 0) if analysis_data else 0\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar linha do arquivo {file_path}: {str(e)}\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exibir estrutura do DataFrame\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Total de registros processados: {len(df)}\")\n",
    "print(\"\\nPrimeiros registros:\")\n",
    "display(df)\n",
    "df.to_csv(\"classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0262",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4a081",
   "metadata": {},
   "source": [
    "### Gerando inferências concretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_group(group):\n",
    "    if group.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extrair metadados fixos do grupo\n",
    "    model = group['model'].iloc[0]\n",
    "    source_file = group['source_file'].iloc[0]\n",
    "    type_ = group['type'].iloc[0]  # Assume que 'type' é consistente no grupo\n",
    "    font = group['font'].iloc[0]   # Assume que 'font' é consistente no grupo\n",
    "\n",
    "    # Contar ocorrências de cada classificação\n",
    "    class_counts = group['classification'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "    \n",
    "    # Identificar classes com contagem máxima (podem ser múltiplas em caso de empate)\n",
    "    top_classes = class_counts[class_counts == max_count].index.tolist()\n",
    "    \n",
    "    # Critério de desempate: priorizar 'INTERESTING'\n",
    "    if len(top_classes) > 1 and 'INTERESTING' in top_classes:\n",
    "        majority_class = 'INTERESTING'\n",
    "    else:\n",
    "        majority_class = class_counts.idxmax()  # Escolhe a classe mais frequente\n",
    "\n",
    "    # Calcular métricas consolidadas\n",
    "    consolidated = pd.DataFrame({\n",
    "        'model': [model],\n",
    "        'font': [font],\n",
    "        'source_file': [source_file],\n",
    "        'type': [type_],\n",
    "        'classification': [majority_class],\n",
    "        'confidence': [group['confidence'].mean()],  # Média das confianças\n",
    "    })\n",
    "    \n",
    "    return consolidated\n",
    "\n",
    "# Carregar e processar dados\n",
    "df = pd.read_csv('classifications.csv')\n",
    "df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "df = df.dropna(subset=['confidence'])\n",
    "\n",
    "# Agrupar por modelo e arquivo, processar e consolidar\n",
    "processed = (\n",
    "    df.groupby(['model', 'source_file'], group_keys=False)  # Agrupamento chave\n",
    "    .apply(process_group)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Ordenar colunas e salvar\n",
    "final_df = processed[['model', 'font', 'source_file', 'type', 'classification', 'confidence']]\n",
    "final_df.to_csv('consolidated_classifications.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839dfaa",
   "metadata": {},
   "source": [
    "## Comitê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe055c7",
   "metadata": {},
   "source": [
    "#### Voto Majoritário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "COMMITTEE   = [\"deepseek-r1_14b\", \"qwen3_14b\", \"phi4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e058cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV   = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV  = \"consolidated_classifications_with_vote.csv\"\n",
    "# 1) Leitura do CSV original\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra só as linhas dos 3 modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)]\n",
    "\n",
    "# 3) Voto majoritário por source_file\n",
    "teste = df_comm.groupby(\"source_file\")[\"classification\"]\n",
    "\n",
    "vote = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\")[\"classification\"]\n",
    "    .agg(lambda x: x.value_counts().idxmax())\n",
    ")\n",
    "\n",
    "# 4) Captura metadados (font e type) pelo primeiro registro de cada grupo\n",
    "meta = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\")\n",
    "    .agg({\n",
    "        \"font\": \"first\",\n",
    "        \"type\": \"first\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# 5) Monta o DataFrame de saída\n",
    "vote_df = pd.DataFrame({\n",
    "    \"model\": \"voto_majoritario\",\n",
    "    \"font\":       meta[\"font\"],\n",
    "    \"source_file\": meta.index,\n",
    "    \"type\":       meta[\"type\"],\n",
    "    \"classification\": vote\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 6) Salva em CSV\n",
    "vote_df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Comitê salvo em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c66760",
   "metadata": {},
   "source": [
    "#### Votação Ponderada por Confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44affc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_vote_classification(group: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Recebe um grupo contendo só um source_file e retorna a classificação\n",
    "    cuja soma de confiança é a maior (votação ponderada).\n",
    "    \"\"\"\n",
    "    # Soma de confiança por label\n",
    "    sums = group.groupby(\"classification\")[\"confidence\"].sum()\n",
    "    # Retorna o índice com maior soma\n",
    "    return sums.idxmax()\n",
    "\n",
    "INPUT_CSV   = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV  = \"consolidated_classifications_with_weighted_vote.csv\"\n",
    "\n",
    "# 1) Carrega o CSV original\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra só os registros dos modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)].copy()\n",
    "\n",
    "# 3) Aplica a função de votação ponderada por grupo (source_file)\n",
    "vote = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\", group_keys=False)\n",
    "    .apply(lambda grp: weighted_vote_classification(grp))\n",
    "    .rename(\"classification\")\n",
    ")\n",
    "\n",
    "# 4) Captura metadados (font e type) pelo primeiro registro de cada grupo\n",
    "meta = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\", as_index=True)\n",
    "    .agg({\n",
    "        \"font\": \"first\",\n",
    "        \"type\": \"first\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# 5) Monta o DataFrame de saída com coluna `model` = \"voto_ponderado\"\n",
    "result = pd.DataFrame({\n",
    "    \"model\": \"voto_ponderado\",\n",
    "    \"font\": meta[\"font\"],\n",
    "    \"source_file\": meta.index,\n",
    "    \"type\": meta[\"type\"],\n",
    "    \"classification\": vote\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 6) Salva o CSV de saída\n",
    "result.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Votação ponderada salva em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daf033",
   "metadata": {},
   "source": [
    "#### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd802a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96109937",
   "metadata": {},
   "source": [
    "#### Seleção Dinâmica de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25878047",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV      = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV     = \"consolidated_classifications_dynamic_selection.csv\"\n",
    "\n",
    "# 1) Carrega todo o CSV\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra apenas as linhas dos modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)].copy()\n",
    "\n",
    "# 3) Para cada source_file, seleciona a linha com maior confidence\n",
    "df_dynamic = (\n",
    "    df_comm\n",
    "    .sort_values([\"source_file\", \"confidence\"], ascending=[True, False])\n",
    "    .groupby(\"source_file\", as_index=False)\n",
    "    .first()\n",
    "    .assign(model=\"selecao_dinamica\")\n",
    ")\n",
    "# 4) Salva o resultado\n",
    "df_dynamic.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Seleção dinâmica salva em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139370d",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd1130",
   "metadata": {},
   "source": [
    "### Gerando métricas finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4791e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "INPUT_FILES = {\n",
    "    \"original\":        \"consolidated_classifications.csv\",\n",
    "    \"dynamic\":         \"consolidated_classifications_dynamic_selection.csv\",\n",
    "    \"vote\":            \"consolidated_classifications_with_vote.csv\",\n",
    "    \"weighted_vote\":   \"consolidated_classifications_with_weighted_vote.csv\",\n",
    "}\n",
    "OUTPUT_FILE = \"all_classifications_combined.csv\"\n",
    "\n",
    "# 1) Carrega cada CSV num DataFrame\n",
    "df_orig      = pd.read_csv(INPUT_FILES[\"original\"])\n",
    "df_dynamic   = pd.read_csv(INPUT_FILES[\"dynamic\"])\n",
    "df_vote      = pd.read_csv(INPUT_FILES[\"vote\"])\n",
    "df_weighted  = pd.read_csv(INPUT_FILES[\"weighted_vote\"])\n",
    "\n",
    "# 2) Concatena verticalmente, mantendo todas as colunas (as que não existirem em algum DF virão como NaN)\n",
    "df_all = pd.concat(\n",
    "    [df_orig, df_dynamic, df_vote, df_weighted],\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    "    sort=False\n",
    ")\n",
    "\n",
    "# 3) (Opcional) Reordena as colunas numa ordem lógica\n",
    "cols_order = [\n",
    "    \"model\", \"font\", \"source_file\", \"type\", \"classification\",\n",
    "    \"confidence\", \"false_positive\", \"false_negative\",\n",
    "    \"true_positive\", \"true_negative\"\n",
    "]\n",
    "# vai incluir também qualquer coluna extra que exista\n",
    "cols_final = [c for c in cols_order if c in df_all.columns] \\\n",
    "                + [c for c in df_all.columns if c not in cols_order]\n",
    "df_all = df_all[cols_final]\n",
    "\n",
    "# 4) Salva o DataFrame combinado\n",
    "df_all.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Todos os registros combinados em: {OUTPUT_FILE}\")\n",
    "\n",
    "final_df = pd.read_csv(\"all_classifications_combined.csv\")\n",
    "\n",
    "final_df[\"false_positive\"] = np.where(\n",
    "    (final_df[\"type\"] == \"safe\") &\n",
    "    (final_df[\"classification\"] == \"INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"false_negative\"] = np.where(\n",
    "    (final_df[\"type\"] == \"attack\") &\n",
    "    (final_df[\"classification\"] == \"NOT INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"true_positive\"] = np.where(\n",
    "    (final_df[\"type\"] == \"attack\") &\n",
    "    (final_df[\"classification\"] == \"INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"true_negative\"] = np.where(\n",
    "    (final_df[\"type\"] == \"safe\") &\n",
    "    (final_df[\"classification\"] == \"NOT INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df.to_csv(\"consolidated_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81decba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o CSV\n",
    "df = pd.read_csv(\"consolidated_classifications.csv\")\n",
    "\n",
    "# Função para calcular métricas por grupo (modelo + fonte)\n",
    "def calcular_metricas(grupo):\n",
    "    y_true = grupo[\"true_positive\"] + grupo[\"true_negative\"] > 0  # se for verdadeiro positivo ou negativo\n",
    "    y_pred = ~grupo[\"false_positive\"].astype(bool)  # predição correta se não for falso positivo\n",
    "\n",
    "    # Isso assume que estamos interessados na predição de INTERESTING como positivo\n",
    "    tp = grupo[\"true_positive\"].sum()\n",
    "    tn = grupo[\"true_negative\"].sum()\n",
    "    fp = grupo[\"false_positive\"].sum()\n",
    "    fn = grupo[\"false_negative\"].sum()\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "\n",
    "    acc = (tp + tn) / total if total else 0\n",
    "    prec = tp / (tp + fp) if (tp + fp) else 0\n",
    "    rec = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1\n",
    "    })\n",
    "\n",
    "# Aplicar por modelo + fonte\n",
    "metricas_por_grupo = df.groupby([\"model\", \"font\"]).apply(calcular_metricas).reset_index()\n",
    "\n",
    "# Exibir\n",
    "display(metricas_por_grupo)\n",
    "metricas_por_grupo.to_csv(\"result_table.csv\", decimal=',', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"consolidated_classifications.csv\")\n",
    "\n",
    "grouped = df.groupby([\"model\", \"font\"])[\n",
    "    [\"false_positive\", \"false_negative\", \"true_positive\", \"true_negative\"]\n",
    "].sum().reset_index()\n",
    "\n",
    "display(grouped)\n",
    "grouped.to_csv(\"result_table_brute.csv\", decimal=',', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
