{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2bcb51c",
   "metadata": {},
   "source": [
    "### Imports e utilitários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00c710f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, glob\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c7321b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÉLULA — Parser robusto p/ JSONL com dicts em string (aspas simples / None)\n",
    "import json, re\n",
    "from ast import literal_eval\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "def _try_literal_eval(s: str) -> Any:\n",
    "    \"\"\"Tenta converter string 'estilo Python' (ex.: \"{'k': 'v'}\", 'None') em objeto Python.\"\"\"\n",
    "    s = s.strip()\n",
    "    if s in (\"None\", \"none\", \"NULL\", \"Null\", \"null\"):\n",
    "        return None\n",
    "    # se parece com dict/list/tuple/num/str python → tenta literal_eval\n",
    "    if (s.startswith(\"{\") and s.endswith(\"}\")) or \\\n",
    "       (s.startswith(\"[\") and s.endswith(\"]\")) or \\\n",
    "       (s.startswith(\"(\") and s.endswith(\")\")) or \\\n",
    "       (s.startswith(\"'\") and s.endswith(\"'\")) or \\\n",
    "       (s.startswith('\"') and s.endswith('\"')):\n",
    "        try:\n",
    "            return literal_eval(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "    # último recurso: se parece com JSON de verdade (aspas duplas), tenta json.loads\n",
    "    if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return s  # mantém como string\n",
    "\n",
    "def _normalize_pyish(obj: Any) -> Any:\n",
    "    \"\"\"Converte recursivamente strings 'pythonizadas' em estruturas Python.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: _normalize_pyish(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [_normalize_pyish(v) for v in obj]\n",
    "    if isinstance(obj, str):\n",
    "        val = _try_literal_eval(obj)\n",
    "        # se mudou de tipo, normaliza de novo (pode ter aninhado)\n",
    "        if val is not obj:\n",
    "            return _normalize_pyish(val)\n",
    "        return obj\n",
    "    return obj\n",
    "\n",
    "def read_jsonl_lines(path: str) -> List[Any]:\n",
    "    \"\"\"Lê JSONL tolerante e normaliza campos-string que são dict/list pythonizados.\"\"\"\n",
    "    out: List[Any] = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for raw in f:\n",
    "            line = raw.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                obj = json.loads(line)\n",
    "            except json.JSONDecodeError:\n",
    "                # linha não é JSON puro; tenta avaliar direto como python literal\n",
    "                obj = _try_literal_eval(line)\n",
    "            obj = _normalize_pyish(obj)\n",
    "            out.append(obj)\n",
    "    return out\n",
    "\n",
    "def event_to_text(evt: Any) -> str:\n",
    "    \"\"\"Extrai texto útil do evento (dict esperado, mas aceita outros tipos).\"\"\"\n",
    "    if isinstance(evt, dict):\n",
    "        parts = []\n",
    "\n",
    "        # winlog.task\n",
    "        winlog = evt.get(\"winlog\")\n",
    "        if isinstance(winlog, dict):\n",
    "            task = winlog.get(\"task\")\n",
    "            if task: parts.append(str(task))\n",
    "        elif isinstance(winlog, str):\n",
    "            parts.append(winlog)\n",
    "\n",
    "        # process.command_line / process.name\n",
    "        proc = evt.get(\"process\")\n",
    "        if isinstance(proc, dict):\n",
    "            cmd = proc.get(\"command_line\")\n",
    "            name = proc.get(\"name\")\n",
    "            if name: parts.append(str(name))\n",
    "            if cmd:  parts.append(str(cmd))\n",
    "        elif isinstance(proc, str):\n",
    "            parts.append(proc)\n",
    "\n",
    "        # file.path/name/target_path\n",
    "        fobj = evt.get(\"file\")\n",
    "        if isinstance(fobj, dict):\n",
    "            for k in (\"path\", \"name\", \"target_path\"):\n",
    "                v = fobj.get(k)\n",
    "                if v: parts.append(str(v))\n",
    "        elif isinstance(fobj, str):\n",
    "            parts.append(fobj)\n",
    "\n",
    "        if parts:\n",
    "            return \" \".join(parts)\n",
    "        # fallback: serializa curto\n",
    "        try: return json.dumps(evt, ensure_ascii=False)\n",
    "        except Exception: return str(evt)\n",
    "\n",
    "    if isinstance(evt, list):\n",
    "        return \"\\n\".join(event_to_text(x) for x in evt)\n",
    "    if isinstance(evt, str):\n",
    "        return evt\n",
    "    try: return json.dumps(evt, ensure_ascii=False)\n",
    "    except Exception: return str(evt)\n",
    "\n",
    "def file_to_document_text(path: str) -> str:\n",
    "    events = read_jsonl_lines(path)\n",
    "    texts = [event_to_text(e) for e in events]\n",
    "    return \"\\n\".join(texts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7288127d",
   "metadata": {},
   "source": [
    "### Montagem do dataset (e fatiamento do benigno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "37f54e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164,\n",
       " ['./attacks\\\\20250815_164702.jsonl',\n",
       "  './attacks\\\\20250815_164734.jsonl',\n",
       "  './attacks\\\\20250815_164800.jsonl'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATTACK_GLOB = \"./attacks/*.jsonl\"\n",
    "BENIGN_FILE = \"./benign/benign.jsonl\"\n",
    "\n",
    "attack_files = sorted(glob.glob(ATTACK_GLOB))\n",
    "assert len(attack_files) > 0, \"Nenhum arquivo encontrado em ./attacks/*.jsonl\"\n",
    "\n",
    "assert os.path.exists(BENIGN_FILE), \"Arquivo benigno ./benign/benign.jsonl não encontrado\"\n",
    "\n",
    "len(attack_files), attack_files[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6195472c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana de linhas (ataque): 31\n",
      "Linhas do benigno: 10000\n",
      "Numero de fatias benignas (K): 500\n"
     ]
    }
   ],
   "source": [
    "attack_line_counts = [count_lines(p) for p in attack_files]\n",
    "median_attack_lines = int(np.median(attack_line_counts)) if attack_line_counts else 500\n",
    "\n",
    "benign_total_lines = count_lines(BENIGN_FILE)\n",
    "\n",
    "# número de pedaços benignos ~ benign_total / mediana_ataque, limitado para não explodir\n",
    "K = 500\n",
    "\n",
    "print(f\"Mediana de linhas (ataque): {median_attack_lines}\")\n",
    "print(f\"Linhas do benigno: {benign_total_lines}\")\n",
    "print(f\"Numero de fatias benignas (K): {K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3701b36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documentos: 1664 | Maliciosos: 1164 | Benignos: 500\n"
     ]
    }
   ],
   "source": [
    "# 1) Documentos de ataque (label=1)\n",
    "X_text, y, ids = [], [], []\n",
    "\n",
    "for path in attack_files:\n",
    "    doc = file_to_document_text(path)\n",
    "    X_text.append(doc)\n",
    "    y.append(1)\n",
    "    ids.append(Path(path).name)\n",
    "\n",
    "# 2) Documentos benignos (label=0), fatiando o arquivo grande\n",
    "benign_lines_raw = read_jsonl_lines(BENIGN_FILE)\n",
    "chunk_size = math.ceil(len(benign_lines_raw) / K)\n",
    "\n",
    "for i in range(K):\n",
    "    chunk = benign_lines_raw[i*chunk_size : (i+1)*chunk_size]\n",
    "    if not chunk:\n",
    "        continue\n",
    "    # transformar o chunk em texto\n",
    "    chunk_texts = [event_to_text(evt) or repr(evt) for evt in chunk]\n",
    "    doc = \"\\n\".join(chunk_texts)\n",
    "    X_text.append(doc)\n",
    "    y.append(0)\n",
    "    ids.append(f\"benign_chunk_{i:03d}\")\n",
    "\n",
    "print(f\"Total documentos: {len(X_text)} | Maliciosos: {sum(y)} | Benignos: {len(y)-sum(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47b26c52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>n_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>20250818_023855.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>6018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>20250815_195101.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>20250815_191937.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>3653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>benign_chunk_058</td>\n",
       "      <td>0</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>20250815_222414.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>1653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>20250826_175043.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>benign_chunk_387</td>\n",
       "      <td>0</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>20250815_222936.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>20250816_011100.jsonl</td>\n",
       "      <td>1</td>\n",
       "      <td>5972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>benign_chunk_234</td>\n",
       "      <td>0</td>\n",
       "      <td>2041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  label  n_chars\n",
       "845   20250818_023855.jsonl      1     6018\n",
       "205   20250815_195101.jsonl      1     7083\n",
       "137   20250815_191937.jsonl      1     3653\n",
       "1222       benign_chunk_058      0     1749\n",
       "492   20250815_222414.jsonl      1     1653\n",
       "960   20250826_175043.jsonl      1        0\n",
       "1551       benign_chunk_387      0     1819\n",
       "508   20250815_222936.jsonl      1      804\n",
       "789   20250816_011100.jsonl      1     5972\n",
       "1398       benign_chunk_234      0     2041"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"id\": ids, \"label\": y, \"n_chars\": [len(t) for t in X_text]})\n",
    "df.sample(min(10, len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa029141",
   "metadata": {},
   "source": [
    "### Split e avaliação auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56109390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(y_test, pred, average=\"binary\", zero_division=0)\n",
    "    print(f\"\\n[{name}]\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision: {pr:.3f} | Recall: {rc:.3f} | F1: {f1:.3f}\")\n",
    "    print(classification_report(y_test, pred, digits=3))\n",
    "    return {\"model\": name, \"accuracy\": acc, \"precision\": pr, \"recall\": rc, \"f1\": f1}\n",
    "\n",
    "# Split estratificado\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Vetorizador compartilhado\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    max_features=100_000,   # limitar um pouco\n",
    "    ngram_range=(1,2),      # unigrams e bigrams\n",
    "    token_pattern=r\"(?u)\\b\\w+\\b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dec537",
   "metadata": {},
   "source": [
    "### Treinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "30bf82cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LogisticRegression]\n",
      "Accuracy: 0.991 | Precision: 0.987 | Recall: 1.000 | F1: 0.994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.970     0.985       100\n",
      "           1      0.987     1.000     0.994       233\n",
      "\n",
      "    accuracy                          0.991       333\n",
      "   macro avg      0.994     0.985     0.989       333\n",
      "weighted avg      0.991     0.991     0.991       333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression (regressor \"softmax\" no multi-classe; aqui binário)\n",
    "logreg = make_pipeline(\n",
    "    vectorizer,\n",
    "    LogisticRegression(max_iter=500, n_jobs=None)  # simples\n",
    ")\n",
    "m1 = evaluate_model(\"LogisticRegression\", logreg, X_train_text, X_test_text, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e6fc7bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[LinearSVC]\n",
      "Accuracy: 0.997 | Precision: 0.996 | Recall: 1.000 | F1: 0.998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.990     0.995       100\n",
      "           1      0.996     1.000     0.998       233\n",
      "\n",
      "    accuracy                          0.997       333\n",
      "   macro avg      0.998     0.995     0.996       333\n",
      "weighted avg      0.997     0.997     0.997       333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVM\n",
    "linsvm = make_pipeline(\n",
    "    vectorizer,\n",
    "    LinearSVC()\n",
    ")\n",
    "m2 = evaluate_model(\"LinearSVC\", linsvm, X_train_text, X_test_text, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7716503c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DecisionTree]\n",
      "Accuracy: 1.000 | Precision: 1.000 | Recall: 1.000 | F1: 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       100\n",
      "           1      1.000     1.000     1.000       233\n",
      "\n",
      "    accuracy                          1.000       333\n",
      "   macro avg      1.000     1.000     1.000       333\n",
      "weighted avg      1.000     1.000     1.000       333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree (tende a underfitting com TF-IDF esparso, mas incluímos)\n",
    "dtree = make_pipeline(\n",
    "    vectorizer,\n",
    "    DecisionTreeClassifier(random_state=42, max_depth=30)\n",
    ")\n",
    "m3 = evaluate_model(\"DecisionTree\", dtree, X_train_text, X_test_text, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "711d0dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[RandomForest]\n",
      "Accuracy: 1.000 | Precision: 1.000 | Recall: 1.000 | F1: 1.000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       100\n",
      "           1      1.000     1.000     1.000       233\n",
      "\n",
      "    accuracy                          1.000       333\n",
      "   macro avg      1.000     1.000     1.000       333\n",
      "weighted avg      1.000     1.000     1.000       333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Random Forest (com TF-IDF esparso nem sempre é ideal, mas funciona)\n",
    "rf = make_pipeline(\n",
    "    vectorizer,\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        max_depth=None\n",
    "    )\n",
    ")\n",
    "m4 = evaluate_model(\"RandomForest\", rf, X_train_text, X_test_text, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "73353b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.987288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  accuracy  precision  recall        f1\n",
       "3        RandomForest  1.000000   1.000000     1.0  1.000000\n",
       "2        DecisionTree  1.000000   1.000000     1.0  1.000000\n",
       "1           LinearSVC  0.996997   0.995726     1.0  0.997859\n",
       "0  LogisticRegression  0.990991   0.987288     1.0  0.993603"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabela comparativa de métricas\n",
    "score_table = pd.DataFrame([m1, m2, m3, m4]).sort_values(\"f1\", ascending=False)\n",
    "score_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d978717",
   "metadata": {},
   "source": [
    "### Salvar o melhor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3baa125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo: ./models/model_LogisticRegression.joblib\n",
      "Salvo: ./models/model_LinearSVC.joblib\n",
      "Salvo: ./models/model_DecisionTree.joblib\n",
      "Salvo: ./models/model_RandomForest.joblib\n",
      "Salvo melhor modelo em: ./models/best_model_RandomForest.joblib\n",
      "Salvo resumo de métricas em: ./models/metrics_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Salvar todos os modelos e também destacar o melhor\n",
    "import os, joblib\n",
    "\n",
    "# dicionário com todos os pipelines treinados\n",
    "all_models = {\n",
    "    \"LogisticRegression\": logreg,\n",
    "    \"LinearSVC\": linsvm,\n",
    "    \"DecisionTree\": dtree,\n",
    "    \"RandomForest\": rf,\n",
    "}\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "# salva cada um\n",
    "for name, pipe in all_models.items():\n",
    "    path = f\"./models/model_{name}.joblib\"\n",
    "    joblib.dump(pipe, path)\n",
    "    print(\"Salvo:\", path)\n",
    "\n",
    "# opcional: salva também o melhor (com base no score_table)\n",
    "best_name = score_table.iloc[0][\"model\"]\n",
    "best_pipe = all_models[best_name]\n",
    "best_path = f\"./models/best_model_{best_name}.joblib\"\n",
    "joblib.dump(best_pipe, best_path)\n",
    "print(\"Salvo melhor modelo em:\", best_path)\n",
    "\n",
    "# opcional: salvar a tabela de métricas para referência\n",
    "score_table.to_csv(\"./models/metrics_summary.csv\", index=False)\n",
    "print(\"Salvo resumo de métricas em: ./models/metrics_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416bad00",
   "metadata": {},
   "source": [
    "### Inferência em novos arquivos/diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Avaliando best_model_RandomForest =====\n",
      "\n",
      "-- Conjunto: attack | pattern=../data/attack/*.jsonl | true=1\n",
      "20250411_175749.jsonl                    => pred=1\n",
      "20250411_175806.jsonl                    => pred=1\n",
      "20250411_175826.jsonl                    => pred=1\n",
      "20250411_175855.jsonl                    => pred=1\n",
      "20250411_175959.jsonl                    => pred=1\n",
      "20250411_180055.jsonl                    => pred=1\n",
      "20250411_180121.jsonl                    => pred=1\n",
      "20250411_180202.jsonl                    => pred=1\n",
      "20250411_180213.jsonl                    => pred=1\n",
      "20250411_180224.jsonl                    => pred=1\n",
      "20250411_180237.jsonl                    => pred=1\n",
      "20250411_180254.jsonl                    => pred=1\n",
      "20250411_180316.jsonl                    => pred=1\n",
      "20250411_180502.jsonl                    => pred=1\n",
      "20250411_180536.jsonl                    => pred=1\n",
      "20250411_180602.jsonl                    => pred=1\n",
      "20250411_180623.jsonl                    => pred=1\n",
      "20250411_180641.jsonl                    => pred=1\n",
      "20250411_180654.jsonl                    => pred=1\n",
      "20250411_180711.jsonl                    => pred=1\n",
      "20250411_180823.jsonl                    => pred=1\n",
      "20250411_180856.jsonl                    => pred=1\n",
      "20250411_180927.jsonl                    => pred=1\n",
      "20250411_180952.jsonl                    => pred=1\n",
      "20250411_181019.jsonl                    => pred=1\n",
      "20250411_181050.jsonl                    => pred=1\n",
      "20250411_181122.jsonl                    => pred=1\n",
      "20250411_181227.jsonl                    => pred=1\n",
      "20250411_181243.jsonl                    => pred=1\n",
      "20250411_181301.jsonl                    => pred=1\n",
      "20250411_181320.jsonl                    => pred=1\n",
      "20250411_181351.jsonl                    => pred=1\n",
      "20250606_143546.jsonl                    => pred=1\n",
      "20250606_143623.jsonl                    => pred=1\n",
      "20250606_143642.jsonl                    => pred=1\n",
      "20250606_143748.jsonl                    => pred=1\n",
      "20250606_143816.jsonl                    => pred=1\n",
      "20250606_143841.jsonl                    => pred=1\n",
      "20250606_143915.jsonl                    => pred=0\n",
      "20250606_143926.jsonl                    => pred=1\n",
      "20250606_143937.jsonl                    => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=1): Acc=0.951 | P=1.000 | R=0.951 | F1=0.975\n",
      "\n",
      "-- Conjunto: safe | pattern=../data/safe/*.jsonl | true=0\n",
      "safe_20250418_134500.jsonl               => pred=1\n",
      "safe_20250418_134601.jsonl               => pred=1\n",
      "safe_20250418_134701.jsonl               => pred=1\n",
      "safe_20250418_134801.jsonl               => pred=1\n",
      "safe_20250418_134901.jsonl               => pred=1\n",
      "safe_20250505_184100.jsonl               => pred=1\n",
      "safe_20250505_185900.jsonl               => pred=1\n",
      "safe_20250505_190800.jsonl               => pred=1\n",
      "safe_20250505_191000.jsonl               => pred=1\n",
      "safe_20250505_191300.jsonl               => pred=1\n",
      "safe_20250505_193400.jsonl               => pred=1\n",
      "safe_20250505_193900.jsonl               => pred=1\n",
      "safe_20250505_194600.jsonl               => pred=1\n",
      "safe_20250505_195000.jsonl               => pred=1\n",
      "safe_20250505_195200.jsonl               => pred=1\n",
      "safe_20250505_195500.jsonl               => pred=1\n",
      "safe_20250505_195700.jsonl               => pred=1\n",
      "safe_20250505_200000.jsonl               => pred=1\n",
      "safe_20250505_200200.jsonl               => pred=1\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=0): Acc=0.000 | P=0.000 | R=0.000 | F1=0.000\n",
      "\n",
      "===== Avaliando model_DecisionTree =====\n",
      "\n",
      "-- Conjunto: attack | pattern=../data/attack/*.jsonl | true=1\n",
      "20250411_175749.jsonl                    => pred=1\n",
      "20250411_175806.jsonl                    => pred=1\n",
      "20250411_175826.jsonl                    => pred=1\n",
      "20250411_175855.jsonl                    => pred=1\n",
      "20250411_175959.jsonl                    => pred=1\n",
      "20250411_180055.jsonl                    => pred=1\n",
      "20250411_180121.jsonl                    => pred=1\n",
      "20250411_180202.jsonl                    => pred=1\n",
      "20250411_180213.jsonl                    => pred=1\n",
      "20250411_180224.jsonl                    => pred=1\n",
      "20250411_180237.jsonl                    => pred=1\n",
      "20250411_180254.jsonl                    => pred=1\n",
      "20250411_180316.jsonl                    => pred=1\n",
      "20250411_180502.jsonl                    => pred=1\n",
      "20250411_180536.jsonl                    => pred=1\n",
      "20250411_180602.jsonl                    => pred=1\n",
      "20250411_180623.jsonl                    => pred=1\n",
      "20250411_180641.jsonl                    => pred=1\n",
      "20250411_180654.jsonl                    => pred=1\n",
      "20250411_180711.jsonl                    => pred=1\n",
      "20250411_180823.jsonl                    => pred=1\n",
      "20250411_180856.jsonl                    => pred=1\n",
      "20250411_180927.jsonl                    => pred=1\n",
      "20250411_180952.jsonl                    => pred=1\n",
      "20250411_181019.jsonl                    => pred=1\n",
      "20250411_181050.jsonl                    => pred=1\n",
      "20250411_181122.jsonl                    => pred=1\n",
      "20250411_181227.jsonl                    => pred=1\n",
      "20250411_181243.jsonl                    => pred=1\n",
      "20250411_181301.jsonl                    => pred=1\n",
      "20250411_181320.jsonl                    => pred=1\n",
      "20250411_181351.jsonl                    => pred=1\n",
      "20250606_143546.jsonl                    => pred=1\n",
      "20250606_143623.jsonl                    => pred=1\n",
      "20250606_143642.jsonl                    => pred=1\n",
      "20250606_143748.jsonl                    => pred=1\n",
      "20250606_143816.jsonl                    => pred=1\n",
      "20250606_143841.jsonl                    => pred=1\n",
      "20250606_143915.jsonl                    => pred=0\n",
      "20250606_143926.jsonl                    => pred=1\n",
      "20250606_143937.jsonl                    => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=1): Acc=0.951 | P=1.000 | R=0.951 | F1=0.975\n",
      "\n",
      "-- Conjunto: safe | pattern=../data/safe/*.jsonl | true=0\n",
      "safe_20250418_134500.jsonl               => pred=1\n",
      "safe_20250418_134601.jsonl               => pred=1\n",
      "safe_20250418_134701.jsonl               => pred=1\n",
      "safe_20250418_134801.jsonl               => pred=1\n",
      "safe_20250418_134901.jsonl               => pred=1\n",
      "safe_20250505_184100.jsonl               => pred=1\n",
      "safe_20250505_185900.jsonl               => pred=0\n",
      "safe_20250505_190800.jsonl               => pred=0\n",
      "safe_20250505_191000.jsonl               => pred=1\n",
      "safe_20250505_191300.jsonl               => pred=1\n",
      "safe_20250505_193400.jsonl               => pred=1\n",
      "safe_20250505_193900.jsonl               => pred=1\n",
      "safe_20250505_194600.jsonl               => pred=1\n",
      "safe_20250505_195000.jsonl               => pred=1\n",
      "safe_20250505_195200.jsonl               => pred=1\n",
      "safe_20250505_195500.jsonl               => pred=1\n",
      "safe_20250505_195700.jsonl               => pred=1\n",
      "safe_20250505_200000.jsonl               => pred=0\n",
      "safe_20250505_200200.jsonl               => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=0): Acc=0.211 | P=0.000 | R=0.000 | F1=0.000\n",
      "\n",
      "===== Avaliando model_LinearSVC =====\n",
      "\n",
      "-- Conjunto: attack | pattern=../data/attack/*.jsonl | true=1\n",
      "20250411_175749.jsonl                    => pred=1\n",
      "20250411_175806.jsonl                    => pred=1\n",
      "20250411_175826.jsonl                    => pred=1\n",
      "20250411_175855.jsonl                    => pred=1\n",
      "20250411_175959.jsonl                    => pred=1\n",
      "20250411_180055.jsonl                    => pred=1\n",
      "20250411_180121.jsonl                    => pred=1\n",
      "20250411_180202.jsonl                    => pred=1\n",
      "20250411_180213.jsonl                    => pred=1\n",
      "20250411_180224.jsonl                    => pred=1\n",
      "20250411_180237.jsonl                    => pred=1\n",
      "20250411_180254.jsonl                    => pred=1\n",
      "20250411_180316.jsonl                    => pred=1\n",
      "20250411_180502.jsonl                    => pred=1\n",
      "20250411_180536.jsonl                    => pred=1\n",
      "20250411_180602.jsonl                    => pred=1\n",
      "20250411_180623.jsonl                    => pred=1\n",
      "20250411_180641.jsonl                    => pred=1\n",
      "20250411_180654.jsonl                    => pred=1\n",
      "20250411_180711.jsonl                    => pred=1\n",
      "20250411_180823.jsonl                    => pred=1\n",
      "20250411_180856.jsonl                    => pred=1\n",
      "20250411_180927.jsonl                    => pred=1\n",
      "20250411_180952.jsonl                    => pred=1\n",
      "20250411_181019.jsonl                    => pred=1\n",
      "20250411_181050.jsonl                    => pred=1\n",
      "20250411_181122.jsonl                    => pred=1\n",
      "20250411_181227.jsonl                    => pred=1\n",
      "20250411_181243.jsonl                    => pred=1\n",
      "20250411_181301.jsonl                    => pred=1\n",
      "20250411_181320.jsonl                    => pred=1\n",
      "20250411_181351.jsonl                    => pred=1\n",
      "20250606_143546.jsonl                    => pred=1\n",
      "20250606_143623.jsonl                    => pred=1\n",
      "20250606_143642.jsonl                    => pred=1\n",
      "20250606_143748.jsonl                    => pred=1\n",
      "20250606_143816.jsonl                    => pred=1\n",
      "20250606_143841.jsonl                    => pred=1\n",
      "20250606_143915.jsonl                    => pred=1\n",
      "20250606_143926.jsonl                    => pred=0\n",
      "20250606_143937.jsonl                    => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=1): Acc=0.951 | P=1.000 | R=0.951 | F1=0.975\n",
      "\n",
      "-- Conjunto: safe | pattern=../data/safe/*.jsonl | true=0\n",
      "safe_20250418_134500.jsonl               => pred=1\n",
      "safe_20250418_134601.jsonl               => pred=1\n",
      "safe_20250418_134701.jsonl               => pred=1\n",
      "safe_20250418_134801.jsonl               => pred=1\n",
      "safe_20250418_134901.jsonl               => pred=1\n",
      "safe_20250505_184100.jsonl               => pred=1\n",
      "safe_20250505_185900.jsonl               => pred=1\n",
      "safe_20250505_190800.jsonl               => pred=1\n",
      "safe_20250505_191000.jsonl               => pred=1\n",
      "safe_20250505_191300.jsonl               => pred=1\n",
      "safe_20250505_193400.jsonl               => pred=1\n",
      "safe_20250505_193900.jsonl               => pred=1\n",
      "safe_20250505_194600.jsonl               => pred=1\n",
      "safe_20250505_195000.jsonl               => pred=1\n",
      "safe_20250505_195200.jsonl               => pred=1\n",
      "safe_20250505_195500.jsonl               => pred=1\n",
      "safe_20250505_195700.jsonl               => pred=1\n",
      "safe_20250505_200000.jsonl               => pred=0\n",
      "safe_20250505_200200.jsonl               => pred=1\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=0): Acc=0.053 | P=0.000 | R=0.000 | F1=0.000\n",
      "\n",
      "===== Avaliando model_LogisticRegression =====\n",
      "\n",
      "-- Conjunto: attack | pattern=../data/attack/*.jsonl | true=1\n",
      "20250411_175749.jsonl                    => pred=1\n",
      "20250411_175806.jsonl                    => pred=1\n",
      "20250411_175826.jsonl                    => pred=1\n",
      "20250411_175855.jsonl                    => pred=1\n",
      "20250411_175959.jsonl                    => pred=1\n",
      "20250411_180055.jsonl                    => pred=1\n",
      "20250411_180121.jsonl                    => pred=1\n",
      "20250411_180202.jsonl                    => pred=1\n",
      "20250411_180213.jsonl                    => pred=1\n",
      "20250411_180224.jsonl                    => pred=1\n",
      "20250411_180237.jsonl                    => pred=1\n",
      "20250411_180254.jsonl                    => pred=1\n",
      "20250411_180316.jsonl                    => pred=1\n",
      "20250411_180502.jsonl                    => pred=1\n",
      "20250411_180536.jsonl                    => pred=1\n",
      "20250411_180602.jsonl                    => pred=1\n",
      "20250411_180623.jsonl                    => pred=1\n",
      "20250411_180641.jsonl                    => pred=1\n",
      "20250411_180654.jsonl                    => pred=1\n",
      "20250411_180711.jsonl                    => pred=1\n",
      "20250411_180823.jsonl                    => pred=1\n",
      "20250411_180856.jsonl                    => pred=1\n",
      "20250411_180927.jsonl                    => pred=1\n",
      "20250411_180952.jsonl                    => pred=1\n",
      "20250411_181019.jsonl                    => pred=1\n",
      "20250411_181050.jsonl                    => pred=1\n",
      "20250411_181122.jsonl                    => pred=1\n",
      "20250411_181227.jsonl                    => pred=1\n",
      "20250411_181243.jsonl                    => pred=1\n",
      "20250411_181301.jsonl                    => pred=1\n",
      "20250411_181320.jsonl                    => pred=1\n",
      "20250411_181351.jsonl                    => pred=1\n",
      "20250606_143546.jsonl                    => pred=1\n",
      "20250606_143623.jsonl                    => pred=1\n",
      "20250606_143642.jsonl                    => pred=1\n",
      "20250606_143748.jsonl                    => pred=1\n",
      "20250606_143816.jsonl                    => pred=1\n",
      "20250606_143841.jsonl                    => pred=1\n",
      "20250606_143915.jsonl                    => pred=1\n",
      "20250606_143926.jsonl                    => pred=0\n",
      "20250606_143937.jsonl                    => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=1): Acc=0.951 | P=1.000 | R=0.951 | F1=0.975\n",
      "\n",
      "-- Conjunto: safe | pattern=../data/safe/*.jsonl | true=0\n",
      "safe_20250418_134500.jsonl               => pred=1\n",
      "safe_20250418_134601.jsonl               => pred=1\n",
      "safe_20250418_134701.jsonl               => pred=1\n",
      "safe_20250418_134801.jsonl               => pred=1\n",
      "safe_20250418_134901.jsonl               => pred=0\n",
      "safe_20250505_184100.jsonl               => pred=1\n",
      "safe_20250505_185900.jsonl               => pred=1\n",
      "safe_20250505_190800.jsonl               => pred=1\n",
      "safe_20250505_191000.jsonl               => pred=1\n",
      "safe_20250505_191300.jsonl               => pred=1\n",
      "safe_20250505_193400.jsonl               => pred=1\n",
      "safe_20250505_193900.jsonl               => pred=1\n",
      "safe_20250505_194600.jsonl               => pred=1\n",
      "safe_20250505_195000.jsonl               => pred=1\n",
      "safe_20250505_195200.jsonl               => pred=1\n",
      "safe_20250505_195500.jsonl               => pred=1\n",
      "safe_20250505_195700.jsonl               => pred=1\n",
      "safe_20250505_200000.jsonl               => pred=0\n",
      "safe_20250505_200200.jsonl               => pred=1\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=0): Acc=0.105 | P=0.000 | R=0.000 | F1=0.000\n",
      "\n",
      "===== Avaliando model_RandomForest =====\n",
      "\n",
      "-- Conjunto: attack | pattern=../data/attack/*.jsonl | true=1\n",
      "20250411_175749.jsonl                    => pred=1\n",
      "20250411_175806.jsonl                    => pred=1\n",
      "20250411_175826.jsonl                    => pred=1\n",
      "20250411_175855.jsonl                    => pred=1\n",
      "20250411_175959.jsonl                    => pred=1\n",
      "20250411_180055.jsonl                    => pred=1\n",
      "20250411_180121.jsonl                    => pred=1\n",
      "20250411_180202.jsonl                    => pred=1\n",
      "20250411_180213.jsonl                    => pred=1\n",
      "20250411_180224.jsonl                    => pred=1\n",
      "20250411_180237.jsonl                    => pred=1\n",
      "20250411_180254.jsonl                    => pred=1\n",
      "20250411_180316.jsonl                    => pred=1\n",
      "20250411_180502.jsonl                    => pred=1\n",
      "20250411_180536.jsonl                    => pred=1\n",
      "20250411_180602.jsonl                    => pred=1\n",
      "20250411_180623.jsonl                    => pred=1\n",
      "20250411_180641.jsonl                    => pred=1\n",
      "20250411_180654.jsonl                    => pred=1\n",
      "20250411_180711.jsonl                    => pred=1\n",
      "20250411_180823.jsonl                    => pred=1\n",
      "20250411_180856.jsonl                    => pred=1\n",
      "20250411_180927.jsonl                    => pred=1\n",
      "20250411_180952.jsonl                    => pred=1\n",
      "20250411_181019.jsonl                    => pred=1\n",
      "20250411_181050.jsonl                    => pred=1\n",
      "20250411_181122.jsonl                    => pred=1\n",
      "20250411_181227.jsonl                    => pred=1\n",
      "20250411_181243.jsonl                    => pred=1\n",
      "20250411_181301.jsonl                    => pred=1\n",
      "20250411_181320.jsonl                    => pred=1\n",
      "20250411_181351.jsonl                    => pred=1\n",
      "20250606_143546.jsonl                    => pred=1\n",
      "20250606_143623.jsonl                    => pred=1\n",
      "20250606_143642.jsonl                    => pred=1\n",
      "20250606_143748.jsonl                    => pred=1\n",
      "20250606_143816.jsonl                    => pred=1\n",
      "20250606_143841.jsonl                    => pred=1\n",
      "20250606_143915.jsonl                    => pred=0\n",
      "20250606_143926.jsonl                    => pred=1\n",
      "20250606_143937.jsonl                    => pred=0\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=1): Acc=0.951 | P=1.000 | R=0.951 | F1=0.975\n",
      "\n",
      "-- Conjunto: safe | pattern=../data/safe/*.jsonl | true=0\n",
      "safe_20250418_134500.jsonl               => pred=1\n",
      "safe_20250418_134601.jsonl               => pred=1\n",
      "safe_20250418_134701.jsonl               => pred=1\n",
      "safe_20250418_134801.jsonl               => pred=1\n",
      "safe_20250418_134901.jsonl               => pred=1\n",
      "safe_20250505_184100.jsonl               => pred=1\n",
      "safe_20250505_185900.jsonl               => pred=1\n",
      "safe_20250505_190800.jsonl               => pred=1\n",
      "safe_20250505_191000.jsonl               => pred=1\n",
      "safe_20250505_191300.jsonl               => pred=1\n",
      "safe_20250505_193400.jsonl               => pred=1\n",
      "safe_20250505_193900.jsonl               => pred=1\n",
      "safe_20250505_194600.jsonl               => pred=1\n",
      "safe_20250505_195000.jsonl               => pred=1\n",
      "safe_20250505_195200.jsonl               => pred=1\n",
      "safe_20250505_195500.jsonl               => pred=1\n",
      "safe_20250505_195700.jsonl               => pred=1\n",
      "safe_20250505_200000.jsonl               => pred=1\n",
      "safe_20250505_200200.jsonl               => pred=1\n",
      "\n",
      "Eval (somente arquivos OK; rótulo verdadeiro=0): Acc=0.000 | P=0.000 | R=0.000 | F1=0.000\n",
      "\n",
      "=== RESUMO DE MÉTRICAS ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>set</th>\n",
       "      <th>n_ok</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>model_DecisionTree</td>\n",
       "      <td>ALL</td>\n",
       "      <td>60</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.821053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>model_LogisticRegression</td>\n",
       "      <td>ALL</td>\n",
       "      <td>60</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.804124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>model_LinearSVC</td>\n",
       "      <td>ALL</td>\n",
       "      <td>60</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best_model_RandomForest</td>\n",
       "      <td>ALL</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>model_RandomForest</td>\n",
       "      <td>ALL</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.672414</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best_model_RandomForest</td>\n",
       "      <td>attack</td>\n",
       "      <td>41</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model_DecisionTree</td>\n",
       "      <td>attack</td>\n",
       "      <td>41</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>model_LinearSVC</td>\n",
       "      <td>attack</td>\n",
       "      <td>41</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>model_LogisticRegression</td>\n",
       "      <td>attack</td>\n",
       "      <td>41</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>model_RandomForest</td>\n",
       "      <td>attack</td>\n",
       "      <td>41</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.95122</td>\n",
       "      <td>0.975000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best_model_RandomForest</td>\n",
       "      <td>safe</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>model_DecisionTree</td>\n",
       "      <td>safe</td>\n",
       "      <td>19</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model_LinearSVC</td>\n",
       "      <td>safe</td>\n",
       "      <td>19</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>model_LogisticRegression</td>\n",
       "      <td>safe</td>\n",
       "      <td>19</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>model_RandomForest</td>\n",
       "      <td>safe</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model     set  n_ok  accuracy  precision   recall  \\\n",
       "5         model_DecisionTree     ALL    60  0.716667   0.722222  0.95122   \n",
       "11  model_LogisticRegression     ALL    60  0.683333   0.696429  0.95122   \n",
       "8            model_LinearSVC     ALL    60  0.666667   0.684211  0.95122   \n",
       "2    best_model_RandomForest     ALL    60  0.650000   0.672414  0.95122   \n",
       "14        model_RandomForest     ALL    60  0.650000   0.672414  0.95122   \n",
       "0    best_model_RandomForest  attack    41  0.951220   1.000000  0.95122   \n",
       "3         model_DecisionTree  attack    41  0.951220   1.000000  0.95122   \n",
       "6            model_LinearSVC  attack    41  0.951220   1.000000  0.95122   \n",
       "9   model_LogisticRegression  attack    41  0.951220   1.000000  0.95122   \n",
       "12        model_RandomForest  attack    41  0.951220   1.000000  0.95122   \n",
       "1    best_model_RandomForest    safe    19  0.000000   0.000000  0.00000   \n",
       "4         model_DecisionTree    safe    19  0.210526   0.000000  0.00000   \n",
       "7            model_LinearSVC    safe    19  0.052632   0.000000  0.00000   \n",
       "10  model_LogisticRegression    safe    19  0.105263   0.000000  0.00000   \n",
       "13        model_RandomForest    safe    19  0.000000   0.000000  0.00000   \n",
       "\n",
       "          f1  \n",
       "5   0.821053  \n",
       "11  0.804124  \n",
       "8   0.795918  \n",
       "2   0.787879  \n",
       "14  0.787879  \n",
       "0   0.975000  \n",
       "3   0.975000  \n",
       "6   0.975000  \n",
       "9   0.975000  \n",
       "12  0.975000  \n",
       "1   0.000000  \n",
       "4   0.000000  \n",
       "7   0.000000  \n",
       "10  0.000000  \n",
       "13  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório salvo em: ./models/eval_reports/all_models_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Testar TODOS os modelos salvos em ./models contra conjuntos de arquivos\n",
    "import os, glob, joblib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "EVAL_SETS = [\n",
    "    (\"../data/attack/*.jsonl\", 1, \"attack\"),\n",
    "    (\"../data/safe/*.jsonl\",   0, \"safe\"),\n",
    "]\n",
    "\n",
    "def eval_df_metrics(df: pd.DataFrame):\n",
    "    \"\"\"Computa métricas binárias em um DataFrame de previsões (somente linhas OK).\"\"\"\n",
    "    ok = df[df[\"status\"] == \"ok\"].copy()\n",
    "    if \"true\" not in ok or ok[\"true\"].isna().all():\n",
    "        return {\"n_ok\": len(ok), \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1\": None}\n",
    "    acc = accuracy_score(ok[\"true\"], ok[\"pred\"])\n",
    "    pr, rc, f1, _ = precision_recall_fscore_support(ok[\"true\"], ok[\"pred\"], average=\"binary\", zero_division=0)\n",
    "    return {\"n_ok\": len(ok), \"accuracy\": acc, \"precision\": pr, \"recall\": rc, \"f1\": f1}\n",
    "\n",
    "def evaluate_all_models(models_dir: str = \"./models\", eval_sets = EVAL_SETS):\n",
    "    model_paths = sorted(glob.glob(os.path.join(models_dir, \"*.joblib\")))\n",
    "    assert model_paths, f\"Nenhum modelo encontrado em {models_dir}\"\n",
    "\n",
    "    per_model_rows = []   # métricas por modelo x conjunto\n",
    "    overall_rows   = []   # concat de previsões para calcular 'geral' por modelo\n",
    "\n",
    "    for mp in model_paths:\n",
    "        name = Path(mp).stem  # ex.: model_LinearSVC ou best_model_LinearSVC\n",
    "        print(f\"\\n===== Avaliando {name} =====\")\n",
    "        clf = joblib.load(mp)\n",
    "\n",
    "        model_all_preds = []  # guardar dfs de cada conjunto para métricas gerais\n",
    "\n",
    "        for pattern, true_label, set_name in eval_sets:\n",
    "            print(f\"\\n-- Conjunto: {set_name} | pattern={pattern} | true={true_label}\")\n",
    "            df_pred = batch_predict_dir(clf, pattern, true_label=true_label)\n",
    "            if df_pred is None:\n",
    "                continue\n",
    "\n",
    "            # salva com identificação do conjunto / modelo\n",
    "            df_pred = df_pred.copy()\n",
    "            df_pred[\"set\"] = set_name\n",
    "            df_pred[\"model\"] = name\n",
    "            model_all_preds.append(df_pred)\n",
    "\n",
    "            m = eval_df_metrics(df_pred)\n",
    "            per_model_rows.append({\n",
    "                \"model\": name, \"set\": set_name, **m\n",
    "            })\n",
    "\n",
    "        # métricas gerais (micro) juntando todos os conjuntos com rótulo conhecido\n",
    "        if model_all_preds:\n",
    "            cat = pd.concat(model_all_preds, ignore_index=True)\n",
    "            cat_known = cat[(cat[\"status\"] == \"ok\") & (~cat[\"true\"].isna())]\n",
    "            if len(cat_known) > 0:\n",
    "                acc = accuracy_score(cat_known[\"true\"], cat_known[\"pred\"])\n",
    "                pr, rc, f1, _ = precision_recall_fscore_support(cat_known[\"true\"], cat_known[\"pred\"],\n",
    "                                                                average=\"binary\", zero_division=0)\n",
    "                per_model_rows.append({\n",
    "                    \"model\": name, \"set\": \"ALL\", \"n_ok\": len(cat_known),\n",
    "                    \"accuracy\": acc, \"precision\": pr, \"recall\": rc, \"f1\": f1\n",
    "                })\n",
    "                overall_rows.append(cat)\n",
    "\n",
    "    metrics_df = pd.DataFrame(per_model_rows).sort_values([\"set\", \"f1\"], ascending=[True, False])\n",
    "    print(\"\\n=== RESUMO DE MÉTRICAS ===\")\n",
    "    display(metrics_df)\n",
    "\n",
    "    # opcional: salvar CSV\n",
    "    os.makedirs(\"./models/eval_reports\", exist_ok=True)\n",
    "    out_csv = \"./models/eval_reports/all_models_metrics.csv\"\n",
    "    metrics_df.to_csv(out_csv, index=False)\n",
    "    print(\"Relatório salvo em:\", out_csv)\n",
    "\n",
    "    # opcional: retornar também as previsões concatenadas (se quiser inspecionar)\n",
    "    preds_concat = pd.concat(overall_rows, ignore_index=True) if overall_rows else None\n",
    "    return metrics_df, preds_concat\n",
    "\n",
    "# Executar\n",
    "all_metrics, all_preds = evaluate_all_models(\"./models\", EVAL_SETS)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
