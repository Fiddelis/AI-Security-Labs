{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55e08d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f08d1ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc749f15",
   "metadata": {},
   "source": [
    "## Redução de linhas por modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7027459f",
   "metadata": {},
   "source": [
    "## Tempo medio de cada modelo por fontes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cda8625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70937f97",
   "metadata": {},
   "source": [
    "## Precisão dos modelos por fontes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85c002",
   "metadata": {},
   "source": [
    "### Inferências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f352986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Total de registros processados: 2705\n",
      "\n",
      "Primeiros registros:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>type</th>\n",
       "      <th>font</th>\n",
       "      <th>source_file</th>\n",
       "      <th>classification</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>data</td>\n",
       "      <td>data/attack/20250411_175749.jsonl</td>\n",
       "      <td>INTERESTING</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>data</td>\n",
       "      <td>data/attack/20250411_175749.jsonl</td>\n",
       "      <td>INTERESTING</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>data</td>\n",
       "      <td>data/attack/20250411_175749.jsonl</td>\n",
       "      <td>INTERESTING</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>data</td>\n",
       "      <td>data/attack/20250411_175806.jsonl</td>\n",
       "      <td>INTERESTING</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>data</td>\n",
       "      <td>data/attack/20250411_175826.jsonl</td>\n",
       "      <td>INTERESTING</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe_20250505_195700.jsonl</td>\n",
       "      <td>safe</td>\n",
       "      <td>filtering/llama3.2_3b/safe/safe_20250505_19570...</td>\n",
       "      <td>NOT INTERESTING</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe_20250505_195700.jsonl</td>\n",
       "      <td>safe</td>\n",
       "      <td>filtering/llama3.2_3b/safe/safe_20250505_19570...</td>\n",
       "      <td>NOT INTERESTING</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe_20250505_195700.jsonl</td>\n",
       "      <td>safe</td>\n",
       "      <td>filtering/llama3.2_3b/safe/safe_20250505_19570...</td>\n",
       "      <td>NOT INTERESTING</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe_20250505_200000.jsonl</td>\n",
       "      <td>safe</td>\n",
       "      <td>filtering/llama3.2_3b/safe/safe_20250505_20000...</td>\n",
       "      <td>NOT INTERESTING</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe_20250505_200200.jsonl</td>\n",
       "      <td>safe</td>\n",
       "      <td>filtering/llama3.2_3b/safe/safe_20250505_20020...</td>\n",
       "      <td>NOT INTERESTING</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2705 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model                        type  font  \\\n",
       "0     deepseek-r1_14b                      attack  data   \n",
       "1     deepseek-r1_14b                      attack  data   \n",
       "2     deepseek-r1_14b                      attack  data   \n",
       "3     deepseek-r1_14b                      attack  data   \n",
       "4     deepseek-r1_14b                      attack  data   \n",
       "...               ...                         ...   ...   \n",
       "2700        qwen3_14b  safe_20250505_195700.jsonl  safe   \n",
       "2701        qwen3_14b  safe_20250505_195700.jsonl  safe   \n",
       "2702        qwen3_14b  safe_20250505_195700.jsonl  safe   \n",
       "2703        qwen3_14b  safe_20250505_200000.jsonl  safe   \n",
       "2704        qwen3_14b  safe_20250505_200200.jsonl  safe   \n",
       "\n",
       "                                            source_file   classification  \\\n",
       "0                     data/attack/20250411_175749.jsonl      INTERESTING   \n",
       "1                     data/attack/20250411_175749.jsonl      INTERESTING   \n",
       "2                     data/attack/20250411_175749.jsonl      INTERESTING   \n",
       "3                     data/attack/20250411_175806.jsonl      INTERESTING   \n",
       "4                     data/attack/20250411_175826.jsonl      INTERESTING   \n",
       "...                                                 ...              ...   \n",
       "2700  filtering/llama3.2_3b/safe/safe_20250505_19570...  NOT INTERESTING   \n",
       "2701  filtering/llama3.2_3b/safe/safe_20250505_19570...  NOT INTERESTING   \n",
       "2702  filtering/llama3.2_3b/safe/safe_20250505_19570...  NOT INTERESTING   \n",
       "2703  filtering/llama3.2_3b/safe/safe_20250505_20000...  NOT INTERESTING   \n",
       "2704  filtering/llama3.2_3b/safe/safe_20250505_20020...  NOT INTERESTING   \n",
       "\n",
       "      confidence  \n",
       "0           0.70  \n",
       "1           0.95  \n",
       "2           0.85  \n",
       "3           0.95  \n",
       "4           0.95  \n",
       "...          ...  \n",
       "2700        0.60  \n",
       "2701        0.80  \n",
       "2702        0.00  \n",
       "2703        0.75  \n",
       "2704        0.00  \n",
       "\n",
       "[2705 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_analysis_data(analysis_str):\n",
    "    # Primeiro tenta com blocos markdown\n",
    "    match = re.search(r\"```json\\s*(\\{.*?\\})\\s*```\", analysis_str, re.DOTALL)\n",
    "    if not match:\n",
    "        # fallback: tenta pegar qualquer JSON com CLASSIFICATION\n",
    "        match = re.search(r\"\\{[^{}]*\\\"CLASSIFICATION\\\"[^{}]*\\}\", analysis_str, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(1 if '```' in match.group(0) else 0))\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "# Encontrar todos os arquivos JSONL no padrão especificado\n",
    "files = glob.glob('inference/**/*.jsonl', recursive=True)\n",
    "\n",
    "data = []\n",
    "\n",
    "for file_path in files:\n",
    "    # Extrair o modelo do caminho do arquivo\n",
    "    path = Path(file_path)\n",
    "    model = path.parts[1]  # Extrai o segundo componente do caminho (inference/{model}/...)\n",
    "    if(path.parts[2] == \"data\"):\n",
    "        font = path.parts[2]\n",
    "        type = path.parts[3]\n",
    "    else:\n",
    "        font = path.parts[2]\n",
    "        type = path.parts[3]\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                record = json.loads(line)\n",
    "                analysis_data = extract_analysis_data(record.get('analysis', ''))\n",
    "\n",
    "                data.append({\n",
    "                    'model': model,\n",
    "                    'type': type,\n",
    "                    'font': font,\n",
    "                    'source_file': record.get('file', ''),\n",
    "                    'classification': analysis_data.get('CLASSIFICATION', \"NOT INTERESTING\") if analysis_data else \"NOT INTERESTING\",\n",
    "                    'confidence': analysis_data.get('CONFIDENCE', 0) if analysis_data else 0\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar linha do arquivo {file_path}: {str(e)}\")\n",
    "\n",
    "# Criar DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Exibir estrutura do DataFrame\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Total de registros processados: {len(df)}\")\n",
    "print(\"\\nPrimeiros registros:\")\n",
    "display(df)\n",
    "df.to_csv(\"classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ad0262",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4a081",
   "metadata": {},
   "source": [
    "### Gerando inferências concretas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c75cf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_21084\\1639364311.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(process_group)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_group(group):\n",
    "    if group.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extrair metadados fixos do grupo\n",
    "    model = group['model'].iloc[0]\n",
    "    source_file = group['source_file'].iloc[0]\n",
    "    type_ = group['type'].iloc[0]  # Assume que 'type' é consistente no grupo\n",
    "    font = group['font'].iloc[0]   # Assume que 'font' é consistente no grupo\n",
    "\n",
    "    # Contar ocorrências de cada classificação\n",
    "    class_counts = group['classification'].value_counts()\n",
    "    max_count = class_counts.max()\n",
    "    \n",
    "    # Identificar classes com contagem máxima (podem ser múltiplas em caso de empate)\n",
    "    top_classes = class_counts[class_counts == max_count].index.tolist()\n",
    "    \n",
    "    # Critério de desempate: priorizar 'INTERESTING'\n",
    "    if len(top_classes) > 1 and 'INTERESTING' in top_classes:\n",
    "        majority_class = 'INTERESTING'\n",
    "    else:\n",
    "        majority_class = class_counts.idxmax()  # Escolhe a classe mais frequente\n",
    "\n",
    "    # Calcular métricas consolidadas\n",
    "    consolidated = pd.DataFrame({\n",
    "        'model': [model],\n",
    "        'font': [font],\n",
    "        'source_file': [source_file],\n",
    "        'type': [type_],\n",
    "        'classification': [majority_class],\n",
    "        'confidence': [group['confidence'].mean()],  # Média das confianças\n",
    "    })\n",
    "    \n",
    "    return consolidated\n",
    "\n",
    "# Carregar e processar dados\n",
    "df = pd.read_csv('classifications.csv')\n",
    "df['confidence'] = pd.to_numeric(df['confidence'], errors='coerce')\n",
    "df = df.dropna(subset=['confidence'])\n",
    "\n",
    "# Agrupar por modelo e arquivo, processar e consolidar\n",
    "processed = (\n",
    "    df.groupby(['model', 'source_file'], group_keys=False)  # Agrupamento chave\n",
    "    .apply(process_group)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Ordenar colunas e salvar\n",
    "final_df = processed[['model', 'font', 'source_file', 'type', 'classification', 'confidence']]\n",
    "final_df.to_csv('consolidated_classifications.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8839dfaa",
   "metadata": {},
   "source": [
    "## Comitê"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe055c7",
   "metadata": {},
   "source": [
    "#### Voto Majoritário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34a1017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações\n",
    "COMMITTEE   = [\"deepseek-r1_14b\", \"qwen3_14b\", \"mistral-nemo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e058cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Comitê salvo em: consolidated_classifications_with_vote.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV   = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV  = \"consolidated_classifications_with_vote.csv\"\n",
    "# 1) Leitura do CSV original\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra só as linhas dos 3 modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)]\n",
    "\n",
    "# 3) Voto majoritário por source_file\n",
    "teste = df_comm.groupby(\"source_file\")[\"classification\"]\n",
    "\n",
    "vote = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\")[\"classification\"]\n",
    "    .agg(lambda x: x.value_counts().idxmax())\n",
    ")\n",
    "\n",
    "# 4) Captura metadados (font e type) pelo primeiro registro de cada grupo\n",
    "meta = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\")\n",
    "    .agg({\n",
    "        \"font\": \"first\",\n",
    "        \"type\": \"first\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# 5) Monta o DataFrame de saída\n",
    "vote_df = pd.DataFrame({\n",
    "    \"model\": \"voto_majoritario\",\n",
    "    \"font\":       meta[\"font\"],\n",
    "    \"source_file\": meta.index,\n",
    "    \"type\":       meta[\"type\"],\n",
    "    \"classification\": vote\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 6) Salva em CSV\n",
    "vote_df.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Comitê salvo em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c66760",
   "metadata": {},
   "source": [
    "#### Votação Ponderada por Confiança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d44affc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Votação ponderada salva em: consolidated_classifications_with_weighted_vote.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_21084\\405435007.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda grp: weighted_vote_classification(grp))\n"
     ]
    }
   ],
   "source": [
    "def weighted_vote_classification(group: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Recebe um grupo contendo só um source_file e retorna a classificação\n",
    "    cuja soma de confiança é a maior (votação ponderada).\n",
    "    \"\"\"\n",
    "    # Soma de confiança por label\n",
    "    sums = group.groupby(\"classification\")[\"confidence\"].sum()\n",
    "    # Retorna o índice com maior soma\n",
    "    return sums.idxmax()\n",
    "\n",
    "INPUT_CSV   = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV  = \"consolidated_classifications_with_weighted_vote.csv\"\n",
    "\n",
    "# 1) Carrega o CSV original\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra só os registros dos modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)].copy()\n",
    "\n",
    "# 3) Aplica a função de votação ponderada por grupo (source_file)\n",
    "vote = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\", group_keys=False)\n",
    "    .apply(lambda grp: weighted_vote_classification(grp))\n",
    "    .rename(\"classification\")\n",
    ")\n",
    "\n",
    "# 4) Captura metadados (font e type) pelo primeiro registro de cada grupo\n",
    "meta = (\n",
    "    df_comm\n",
    "    .groupby(\"source_file\", as_index=True)\n",
    "    .agg({\n",
    "        \"font\": \"first\",\n",
    "        \"type\": \"first\"\n",
    "    })\n",
    ")\n",
    "\n",
    "# 5) Monta o DataFrame de saída com coluna `model` = \"voto_ponderado\"\n",
    "result = pd.DataFrame({\n",
    "    \"model\": \"voto_ponderado\",\n",
    "    \"font\": meta[\"font\"],\n",
    "    \"source_file\": meta.index,\n",
    "    \"type\": meta[\"type\"],\n",
    "    \"classification\": vote\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "# 6) Salva o CSV de saída\n",
    "result.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Votação ponderada salva em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61daf033",
   "metadata": {},
   "source": [
    "#### Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd802a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96109937",
   "metadata": {},
   "source": [
    "#### Seleção Dinâmica de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25878047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Seleção dinâmica salva em: consolidated_classifications_dynamic_selection.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV      = \"consolidated_classifications.csv\"\n",
    "OUTPUT_CSV     = \"consolidated_classifications_dynamic_selection.csv\"\n",
    "\n",
    "# 1) Carrega todo o CSV\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "# 2) Filtra apenas as linhas dos modelos do comitê\n",
    "df_comm = df[df[\"model\"].isin(COMMITTEE)].copy()\n",
    "\n",
    "# 3) Para cada source_file, seleciona a linha com maior confidence\n",
    "df_dynamic = (\n",
    "    df_comm\n",
    "    .sort_values([\"source_file\", \"confidence\"], ascending=[True, False])\n",
    "    .groupby(\"source_file\", as_index=False)\n",
    "    .first()\n",
    "    .assign(model=\"selecao_dinamica\")\n",
    ")\n",
    "# 4) Salva o resultado\n",
    "df_dynamic.to_csv(OUTPUT_CSV, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Seleção dinâmica salva em: {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139370d",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fd1130",
   "metadata": {},
   "source": [
    "### Gerando métricas finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4791e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Todos os registros combinados em: all_classifications_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "INPUT_FILES = {\n",
    "    \"original\":        \"consolidated_classifications.csv\",\n",
    "    \"dynamic\":         \"consolidated_classifications_dynamic_selection.csv\",\n",
    "    \"vote\":            \"consolidated_classifications_with_vote.csv\",\n",
    "    \"weighted_vote\":   \"consolidated_classifications_with_weighted_vote.csv\",\n",
    "}\n",
    "OUTPUT_FILE = \"all_classifications_combined.csv\"\n",
    "\n",
    "# 1) Carrega cada CSV num DataFrame\n",
    "df_orig      = pd.read_csv(INPUT_FILES[\"original\"])\n",
    "df_dynamic   = pd.read_csv(INPUT_FILES[\"dynamic\"])\n",
    "df_vote      = pd.read_csv(INPUT_FILES[\"vote\"])\n",
    "df_weighted  = pd.read_csv(INPUT_FILES[\"weighted_vote\"])\n",
    "\n",
    "# 2) Concatena verticalmente, mantendo todas as colunas (as que não existirem em algum DF virão como NaN)\n",
    "df_all = pd.concat(\n",
    "    [df_orig, df_dynamic, df_vote, df_weighted],\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    "    sort=False\n",
    ")\n",
    "\n",
    "# 3) (Opcional) Reordena as colunas numa ordem lógica\n",
    "cols_order = [\n",
    "    \"model\", \"font\", \"source_file\", \"type\", \"classification\",\n",
    "    \"confidence\", \"false_positive\", \"false_negative\",\n",
    "    \"true_positive\", \"true_negative\"\n",
    "]\n",
    "# vai incluir também qualquer coluna extra que exista\n",
    "cols_final = [c for c in cols_order if c in df_all.columns] \\\n",
    "                + [c for c in df_all.columns if c not in cols_order]\n",
    "df_all = df_all[cols_final]\n",
    "\n",
    "# 4) Salva o DataFrame combinado\n",
    "df_all.to_csv(OUTPUT_FILE, index=False, encoding=\"utf-8\")\n",
    "print(f\"✅ Todos os registros combinados em: {OUTPUT_FILE}\")\n",
    "\n",
    "final_df = pd.read_csv(\"all_classifications_combined.csv\")\n",
    "\n",
    "final_df[\"false_positive\"] = np.where(\n",
    "    (final_df[\"type\"] == \"safe\") &\n",
    "    (final_df[\"classification\"] == \"INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"false_negative\"] = np.where(\n",
    "    (final_df[\"type\"] == \"attack\") &\n",
    "    (final_df[\"classification\"] == \"NOT INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"true_positive\"] = np.where(\n",
    "    (final_df[\"type\"] == \"attack\") &\n",
    "    (final_df[\"classification\"] == \"INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df[\"true_negative\"] = np.where(\n",
    "    (final_df[\"type\"] == \"safe\") &\n",
    "    (final_df[\"classification\"] == \"NOT INTERESTING\"),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "final_df.to_csv(\"consolidated_classifications.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81decba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lucas\\AppData\\Local\\Temp\\ipykernel_21084\\3569469697.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  metricas_por_grupo = df.groupby([\"model\", \"font\"]).apply(calcular_metricas).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>font</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>data</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>data</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>data</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4</td>\n",
       "      <td>data</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.828283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>data</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>data</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>data</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>attack</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>data</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>safe</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    font  accuracy  precision    recall  f1_score\n",
       "0    deepseek-r1_14b  attack  0.000000   0.000000  0.000000  0.000000\n",
       "1    deepseek-r1_14b    data  0.816667   0.826087  0.926829  0.873563\n",
       "2    deepseek-r1_14b    safe  0.000000   0.000000  0.000000  0.000000\n",
       "3           llama3.1  attack  0.000000   0.000000  0.000000  0.000000\n",
       "4           llama3.1    data  0.683333   0.683333  1.000000  0.811881\n",
       "5           llama3.1    safe  0.000000   0.000000  0.000000  0.000000\n",
       "6       mistral-nemo  attack  0.000000   0.000000  0.000000  0.000000\n",
       "7       mistral-nemo    data  0.683333   0.683333  1.000000  0.811881\n",
       "8       mistral-nemo    safe  0.000000   0.000000  0.000000  0.000000\n",
       "9               phi4  attack  0.000000   0.000000  0.000000  0.000000\n",
       "10              phi4    data  0.716667   0.706897  1.000000  0.828283\n",
       "11              phi4    safe  0.000000   0.000000  0.000000  0.000000\n",
       "12         qwen3_14b  attack  0.000000   0.000000  0.000000  0.000000\n",
       "13         qwen3_14b    data  0.733333   0.804878  0.804878  0.804878\n",
       "14         qwen3_14b    safe  0.000000   0.000000  0.000000  0.000000\n",
       "15  selecao_dinamica  attack  0.000000   0.000000  0.000000  0.000000\n",
       "16  selecao_dinamica    data  0.766667   0.745455  1.000000  0.854167\n",
       "17  selecao_dinamica    safe  0.000000   0.000000  0.000000  0.000000\n",
       "18  voto_majoritario  attack  0.000000   0.000000  0.000000  0.000000\n",
       "19  voto_majoritario    data  0.766667   0.754717  0.975610  0.851064\n",
       "20  voto_majoritario    safe  0.000000   0.000000  0.000000  0.000000\n",
       "21    voto_ponderado  attack  0.000000   0.000000  0.000000  0.000000\n",
       "22    voto_ponderado    data  0.766667   0.745455  1.000000  0.854167\n",
       "23    voto_ponderado    safe  0.000000   0.000000  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o CSV\n",
    "df = pd.read_csv(\"consolidated_classifications.csv\")\n",
    "\n",
    "# Função para calcular métricas por grupo (modelo + fonte)\n",
    "def calcular_metricas(grupo):\n",
    "    y_true = grupo[\"true_positive\"] + grupo[\"true_negative\"] > 0  # se for verdadeiro positivo ou negativo\n",
    "    y_pred = ~grupo[\"false_positive\"].astype(bool)  # predição correta se não for falso positivo\n",
    "\n",
    "    # Isso assume que estamos interessados na predição de INTERESTING como positivo\n",
    "    tp = grupo[\"true_positive\"].sum()\n",
    "    tn = grupo[\"true_negative\"].sum()\n",
    "    fp = grupo[\"false_positive\"].sum()\n",
    "    fn = grupo[\"false_negative\"].sum()\n",
    "\n",
    "    total = tp + tn + fp + fn\n",
    "\n",
    "    acc = (tp + tn) / total if total else 0\n",
    "    prec = tp / (tp + fp) if (tp + fp) else 0\n",
    "    rec = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1 = 2 * (prec * rec) / (prec + rec) if (prec + rec) else 0\n",
    "\n",
    "    return pd.Series({\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1\n",
    "    })\n",
    "\n",
    "# Aplicar por modelo + fonte\n",
    "metricas_por_grupo = df.groupby([\"model\", \"font\"]).apply(calcular_metricas).reset_index()\n",
    "\n",
    "# Exibir\n",
    "display(metricas_por_grupo)\n",
    "metricas_por_grupo.to_csv(\"result_table.csv\", decimal=',', sep=';', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf47ef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>font</th>\n",
       "      <th>false_positive</th>\n",
       "      <th>false_negative</th>\n",
       "      <th>true_positive</th>\n",
       "      <th>true_negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>data</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deepseek-r1_14b</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>data</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama3.1</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>data</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mistral-nemo</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>phi4</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>phi4</td>\n",
       "      <td>data</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>phi4</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>data</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>qwen3_14b</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>data</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>selecao_dinamica</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>data</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>voto_majoritario</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>attack</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>data</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>voto_ponderado</td>\n",
       "      <td>safe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model    font  false_positive  false_negative  true_positive  \\\n",
       "0    deepseek-r1_14b  attack               0               0              0   \n",
       "1    deepseek-r1_14b    data               8               3             38   \n",
       "2    deepseek-r1_14b    safe               0               0              0   \n",
       "3           llama3.1  attack               0               0              0   \n",
       "4           llama3.1    data              19               0             41   \n",
       "5           llama3.1    safe               0               0              0   \n",
       "6       mistral-nemo  attack               0               0              0   \n",
       "7       mistral-nemo    data              19               0             41   \n",
       "8       mistral-nemo    safe               0               0              0   \n",
       "9               phi4  attack               0               0              0   \n",
       "10              phi4    data              17               0             41   \n",
       "11              phi4    safe               0               0              0   \n",
       "12         qwen3_14b  attack               0               0              0   \n",
       "13         qwen3_14b    data               8               8             33   \n",
       "14         qwen3_14b    safe               0               0              0   \n",
       "15  selecao_dinamica  attack               0               0              0   \n",
       "16  selecao_dinamica    data              14               0             41   \n",
       "17  selecao_dinamica    safe               0               0              0   \n",
       "18  voto_majoritario  attack               0               0              0   \n",
       "19  voto_majoritario    data              13               1             40   \n",
       "20  voto_majoritario    safe               0               0              0   \n",
       "21    voto_ponderado  attack               0               0              0   \n",
       "22    voto_ponderado    data              14               0             41   \n",
       "23    voto_ponderado    safe               0               0              0   \n",
       "\n",
       "    true_negative  \n",
       "0               0  \n",
       "1              11  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  \n",
       "10              2  \n",
       "11              0  \n",
       "12              0  \n",
       "13             11  \n",
       "14              0  \n",
       "15              0  \n",
       "16              5  \n",
       "17              0  \n",
       "18              0  \n",
       "19              6  \n",
       "20              0  \n",
       "21              0  \n",
       "22              5  \n",
       "23              0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"consolidated_classifications.csv\")\n",
    "\n",
    "grouped = df.groupby([\"model\", \"font\"])[\n",
    "    [\"false_positive\", \"false_negative\", \"true_positive\", \"true_negative\"]\n",
    "].sum().reset_index()\n",
    "\n",
    "display(grouped)\n",
    "grouped.to_csv(\"result_table_brute.csv\", decimal=',', sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
